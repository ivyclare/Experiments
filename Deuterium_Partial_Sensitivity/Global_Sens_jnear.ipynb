{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "265391f1",
   "metadata": {},
   "source": [
    "# Section 5.2: Partial sensitivity modelling in (DP-)SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0578d7a9-e41b-48c6-aafd-d76b02f79e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from deuterium import Variable, to_vec, random_symbols, get_gradients\n",
    "from sympy import sympify\n",
    "from scipy.optimize import shgo\n",
    "\n",
    "\n",
    "import symengine as se\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sys\n",
    "sys.setrecursionlimit(1_000_000)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5bf6a8",
   "metadata": {},
   "source": [
    "Define some utility functions, notably the loss functions and tempered sigmoid activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2bb4db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_data = np.vectorize(lambda x: x.data)\n",
    "\n",
    "def sigmoid(x, s=1, T=1, o=0):\n",
    "        return (s/(1+np.exp(-T*x)))-o\n",
    "\n",
    "def tanh(x):\n",
    "    return sigmoid(x, 2, 2, 1)\n",
    "\n",
    "bce_loss = lambda y_pred, y_true: -np.mean(np.multiply(y_true, np.log(y_pred)) + np.multiply((1 - y_true), np.log(1 - y_pred)))\n",
    "normalize = lambda x: (x-x.min())/(x.max()-x.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257e70aa",
   "metadata": {},
   "source": [
    "Define the network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2204290-0606-4cbc-be65-a411b7b0f297",
   "metadata": {},
   "outputs": [],
   "source": [
    "IN=2\n",
    "INTERMEDIATE=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12062985-1289-4617-95e4-b31b8b5e1e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates symbolic representations for all the layers\n",
    "x = to_vec(np.array(random_symbols(IN, \"x\")).reshape((1,IN))) \n",
    "y = to_vec(np.array(random_symbols(1, \"y\")))\n",
    "\n",
    "w1 = to_vec(np.array(random_symbols(IN*INTERMEDIATE, \"w1\")).reshape(IN, INTERMEDIATE))\n",
    "b = to_vec(np.array(random_symbols(INTERMEDIATE, \"b\")).reshape(1, INTERMEDIATE))\n",
    "w2 = to_vec(np.array(random_symbols(INTERMEDIATE, \"w2\")).reshape(INTERMEDIATE,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ddbd573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This replaces some of the variables with *values*\n",
    "# w1 (weights layer 1)\n",
    "# w2 (weights layer 2)\n",
    "# b (bias terms)\n",
    "# y (label)\n",
    "\n",
    "w1 = to_vec(np.random.normal(size=IN*INTERMEDIATE).reshape(IN, INTERMEDIATE))\n",
    "b = to_vec(np.random.normal(size=INTERMEDIATE).reshape(1, INTERMEDIATE))\n",
    "w2 = to_vec(np.random.normal(size=INTERMEDIATE).reshape(INTERMEDIATE,1))\n",
    "y = to_vec(np.array(1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed8e79c",
   "metadata": {},
   "source": [
    "Symbolically calculate the network output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ca12457-4d87-406e-bcb7-702b8f1d9f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_1 = sigmoid(x@w1)+b\n",
    "y_pred = sigmoid(layer_1@w2)\n",
    "loss = bce_loss(y_pred, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875cd7fc",
   "metadata": {},
   "source": [
    "Obtain the gradients w.r.t all inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57520b42-d718-4676-a870-3113e7e9320c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "611de348-7329-40d1-8c67-847dcc8b3f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_grad = np.array([i.grad for i in x.flatten().tolist()])\n",
    "y_grad = np.array([i.grad for i in y.flatten().tolist()])\n",
    "w1_grad = np.array([i.grad for i in w1.flatten().tolist()])\n",
    "b_grad = np.array([i.grad for i in b.flatten().tolist()])\n",
    "w2_grad = np.array([i.grad for i in w2.flatten().tolist()])\n",
    "\n",
    "full_grad = to_vec(np.concatenate((x_grad, y_grad, w1_grad, b_grad, w2_grad)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "396489c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the gradient we care about is just wrt the weights\n",
    "\n",
    "my_grad = to_vec(np.concatenate((w1_grad, b_grad, w2_grad)))\n",
    "len(my_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e6a335",
   "metadata": {},
   "source": [
    "# Optimize the Gradient Norm one Element at a Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4acc417e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{x_1, x_0}\n",
      "[0.0, 0.0, 0.0, 0.0, 0.021051515390329727, 0.3168526122151559, 0.06569637159210578, 0.017294591974371054]\n",
      "CPU times: user 14.2 ms, sys: 427 Âµs, total: 14.6 ms\n",
      "Wall time: 13.6 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6487642801295109"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(np.sum(my_grad).data.free_symbols)\n",
    "intervals = [(-1, 1) for _ in np.sum(my_grad).data.free_symbols]\n",
    "\n",
    "elems = []\n",
    "for g in my_grad:\n",
    "    gp = g**2\n",
    "    f = se.Lambdify(list(gp.data.free_symbols), gp.data)\n",
    "    sol = shgo(f, intervals)\n",
    "    elems.append(sol.fun)\n",
    "\n",
    "print(elems)\n",
    "np.sqrt(np.sum(elems))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953b36d8",
   "metadata": {},
   "source": [
    "# Optimize the Gradient Norm all at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13ce387f",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_grad_norm = np.linalg.norm(my_grad, ord=2)\n",
    "my_grad_norm.data.free_symbols\n",
    "my_grad_norm_func = se.Lambdify(list(my_grad_norm.data.free_symbols), my_grad_norm.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf675f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{x_1, x_0}\n",
      "CPU times: user 2.93 ms, sys: 0 ns, total: 2.93 ms\n",
      "Wall time: 2.39 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6917728201880243"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(my_grad_norm.data.free_symbols)\n",
    "intervals = [(-1, 1) for _ in my_grad_norm.data.free_symbols]\n",
    "sol = shgo(my_grad_norm_func, intervals)\n",
    "sol.fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751a077b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
